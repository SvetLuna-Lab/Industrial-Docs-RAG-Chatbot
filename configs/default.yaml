# configs/default.yaml

embedding:
  # Sentence-transformers model used to build document embeddings
  model_name: sentence-transformers/all-MiniLM-L6-v2
  # For now we keep everything on CPU for portability
  device: cpu
  # Batch size for encoding chunks
  batch_size: 16

retrieval:
  # Number of top chunks to retrieve for each query
  top_k: 5

llm:
  # LLM backend configuration for the /chat endpoint.
  # To run in pure stub mode (no external calls), set:
  # provider: stub
  provider: openai
  # Target model name for the OpenAI-compatible endpoint
  model_name: gpt-4o-mini
  # OpenAI-compatible API base URL
  api_base: "https://api.openai.com/v1"
  # Environment variable that stores the API key
  api_key_env: OPENAI_API_KEY
